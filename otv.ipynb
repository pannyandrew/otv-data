{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline TV Project\n",
    "\n",
    "*Author: Andrew Pan*\n",
    "\n",
    "**Reading in OfflineTV Channel Video Statistics**\n",
    "\n",
    "Source: [SocialBlade OfflineTV](https://socialblade.com/youtube/channel/UCDK9qD5DAQML-pzrtA7A4oA/videos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get statistics of the video\n",
    "def get_stats(url):\n",
    "    #get url\n",
    "    page = requests.get(url)\n",
    "    ary = []\n",
    "    #get title\n",
    "    title = re.search(\"property=\\\"og:title\\\" content=\\\"([^\\n]*)\", page.text).group(1)\n",
    "    title = title[:-2]\n",
    "    ary.append(title)\n",
    "    #get thumbnail\n",
    "    image = re.search(\"property=\\\"og:image\\\" content=\\\"([^\\n]*)\", page.text).group(1)\n",
    "    image = image[:-2]\n",
    "    ary.append(image)\n",
    "    #get tags\n",
    "    tags = re.findall(\"property=\\\"og:video:tag\\\" content=\\\"([^\\n]*)\", page.text)\n",
    "    newtags = []\n",
    "    for x in tags:\n",
    "        newtags.append(x[:-2])\n",
    "    tag = \",\".join(newtags)\n",
    "    ary.append(newtags)\n",
    "    #get upload date\n",
    "    start_date = page.text.index('uploadDate')\n",
    "    stop_date = page.text.index('trackingParams', start_date)\n",
    "    date = page.text[start_date:stop_date]\n",
    "    date = date[15:-7]\n",
    "    ary.append(date)\n",
    "    #get description\n",
    "    start_desc = page.text.index('shortDescription')\n",
    "    stop_desc = page.text.index('isCrawlable')\n",
    "    desc = page.text[start_desc:stop_desc]\n",
    "    desc = desc[20:-5]\n",
    "    ary.append(desc)\n",
    "    #get view count\n",
    "    start_view = page.text.index('viewCount')\n",
    "    stop_view = page.text.index('author')\n",
    "    views = page.text[start_view:stop_view]\n",
    "    views = views[14:-5]\n",
    "    ary.append(views)\n",
    "    #get length of video\n",
    "    start_time = page.text.index('lengthSeconds')\n",
    "    stop_time = page.text.index('keywords')\n",
    "    time = page.text[start_time:stop_time]\n",
    "    time = time[18:-5]\n",
    "    ary.append(time)\n",
    "    #get number of likes\n",
    "    start_like = page.text.index('iconType\\\":\"LIKE\\\"')\n",
    "    stop_like = page.text.index(\"likes\", start_like)\n",
    "    like = page.text[start_like:stop_like]\n",
    "    like = like[80:]\n",
    "    ary.append(like)\n",
    "    #get number of dislikes\n",
    "    start_dislike = page.text.index('iconType\\\":\"DISLIKE\\\"')\n",
    "    stop_dislike = page.text.index(\"dislikes\", start_like)\n",
    "    dislike = page.text[start_dislike:stop_dislike]\n",
    "    dislike = dislike[83:]\n",
    "    ary.append(dislike)\n",
    "\n",
    "    return ary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\"https://www.youtube.com/watch?v=anFz_6oRwI8&t=77s\", \"https://www.youtube.com/watch?v=WdtaiyxMsbs\", \n",
    "            \"https://www.youtube.com/watch?v=kET40pMzaYE\", \"https://www.youtube.com/watch?v=_P6YOzYhlmA\",\n",
    "           \"https://www.youtube.com/watch?v=mJ76Ej4KsX0\", \"https://www.youtube.com/watch?v=4oyVsqIbMgc\",\n",
    "           \"https://www.youtube.com/watch?v=o0nD40qMHHw\", \"https://www.youtube.com/watch?v=UQfNiiJgmno\",\n",
    "           \"https://www.youtube.com/watch?v=qz64WP9Wb94\", \"https://www.youtube.com/watch?v=bFVF4n-JAFA\",\n",
    "           \"https://www.youtube.com/watch?v=5EaE3kN7nUY\", \"https://www.youtube.com/watch?v=Ap5cnkclUsA\",\n",
    "           \"https://www.youtube.com/watch?v=AuZJlroSSHY\", \"https://www.youtube.com/watch?v=P52mr4xRTh8\",\n",
    "           \"https://www.youtube.com/watch?v=llAnpFV2W4g\", \"https://www.youtube.com/watch?v=Efe7oLo1sKc\",\n",
    "           \"https://www.youtube.com/watch?v=cZgMiuIEA8E\", \"https://www.youtube.com/watch?v=1buDltZ6yzU\",\n",
    "           \"https://www.youtube.com/watch?v=pfeKQMlFWNo\", \"https://www.youtube.com/watch?v=ft6W28g2KpE\",\n",
    "           \"https://www.youtube.com/watch?v=4ScktvmY4GQ\", \"https://www.youtube.com/watch?v=GSgnFUPZOrI\",\n",
    "           \"https://www.youtube.com/watch?v=nD40bUeU8OM\", \"https://www.youtube.com/watch?v=GfFVJyDVZuQ\",\n",
    "           \"https://www.youtube.com/watch?v=4ZmrbPVqpNo\", \"https://www.youtube.com/watch?v=63oUHCoADLg\",\n",
    "           \"https://www.youtube.com/watch?v=hVgcacw9hTE\", \"https://www.youtube.com/watch?v=DoS9Wjp1D9M\",\n",
    "           \"https://www.youtube.com/watch?v=Ws6beaoG1mw\", \"https://www.youtube.com/watch?v=yZKMh2OejdY\",\n",
    "           \"https://www.youtube.com/watch?v=99lyzSWePSw\", \"https://www.youtube.com/watch?v=1bOUY9KWwbc\"]\n",
    "\n",
    "data = []\n",
    "for url in url_list:\n",
    "    data.append(get_stats(url))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, [\"title\", \"thumbnail\", \"tags\", \"upload-date\", \"description\", \"view-count\", \"duration\", \"likes\", \"dislikes\"])\n",
    "\n",
    "with open('otv_data.csv', 'w', encoding = 'utf-8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads data from csv file\n",
    "otv_df = pd.read_csv('otv_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does View Count Grow as Time Goes On?\n",
    "\n",
    "### According to this plot, the number of views is seemingly unrelated to how long this channel exists.\n",
    "![Plot](graphs/views_over_time.png)\n",
    "\n",
    "**Using linear regression to predict the number of views on the next video would not be effective.**\n",
    "\n",
    "*run the cells below to get the plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "register_matplotlib_converters()\n",
    "\n",
    "#convert upload date to datetime\n",
    "otv_df['upload-date'] = pd.to_datetime(otv_df['upload-date'])\n",
    "\n",
    "#plotting number of views as a function of time\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "plt.scatter(otv_df['upload-date'], otv_df['view-count'])\n",
    "plt.suptitle('Number of Views by Date', fontsize=26)\n",
    "plt.xlabel('Date', fontsize=16)\n",
    "plt.ylabel('Number of Views', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does View Count vary with the Duration of the Video?\n",
    "\n",
    "### According to this plot...\n",
    "![Plot](graphs/views_for_seconds.png)\n",
    "\n",
    "**no.**  \n",
    "what's next? likes, dislikes, comments, etc.  \n",
    "  \n",
    "*run the cells below for the plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting view count with respect to the duration of the video\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "plt.scatter(otv_df['duration'], otv_df['view-count'])\n",
    "plt.suptitle('Number of Views in relation to Duration', fontsize=26)\n",
    "plt.xlabel('Duration(seconds)', fontsize=16)\n",
    "plt.ylabel('Number of Views', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#making new columns, like and dislike ratios\n",
    "#removing commas from numbers\n",
    "otv_df['likes'] = otv_df['likes'].apply(lambda x: x.replace(\",\",\"\"))\n",
    "otv_df['dislikes'] = otv_df['dislikes'].apply(lambda x: x.replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "dislike_avg": "1.03",
     "like_avg": "98.97"
    }
   },
   "source": [
    "## Here are some statistics about the ratings.\n",
    "### According to plots regarding number of likes and dislikes by video...\n",
    "**There isn't any relationship between number of likes, dislikes, or total ratings and date uploaded.**  \n",
    "However, there appears to be a slight positive relationship between the percentage of raters/viewers and date uploaded  \n",
    "![Plot](graphs/rate_ratio_over_time.png)    \n",
    "Equation of the Line: $y = (5.042e-07)x^2 - 0.7436x + (2.742e+05)$  \n",
    "Here are some general statistics about likes/dislikes\n",
    "- Average Like Percentage: {{like_avg}}%\n",
    "- Average Dislike Percentage {{dislike_avg}}%  \n",
    "  \n",
    "*run the cells below for the plots and statistics* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting strings to ints\n",
    "otv_df['likes'] = pd.to_numeric(otv_df['likes'])\n",
    "otv_df['dislikes'] = pd.to_numeric(otv_df['dislikes'])\n",
    "#new columns\n",
    "otv_df['like-ratio'] = otv_df['likes'] / (otv_df['likes'] + otv_df['dislikes'])\n",
    "otv_df['dislike-ratio'] = 1 - otv_df['like-ratio']\n",
    "otv_df['ratings'] = otv_df['likes'] + otv_df['dislikes']\n",
    "otv_df['rate-ratio'] = otv_df['ratings'] / otv_df['view-count']\n",
    "#replace &#39; with '\n",
    "otv_df['title'] = otv_df['title'].apply(lambda x: x.replace(\"&#39;\",\"'\"))\n",
    "otv_df['title'] = otv_df['title'].apply(lambda x: x.replace(\"&amp;\",\"&\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of likes with relation to time\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.scatter(otv_df['upload-date'], otv_df['likes'])\n",
    "plt.suptitle('Likes by Date', fontsize=26)\n",
    "plt.xlabel('Date', fontsize=16)\n",
    "plt.ylabel('Likes', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of dislikes with relation to time\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.scatter(otv_df['upload-date'], otv_df['dislikes'])\n",
    "plt.suptitle('Dislikes by Date', fontsize=26)\n",
    "plt.xlabel('Date', fontsize=16)\n",
    "plt.ylabel('Dislikes', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of ratings with relation to time\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.scatter(otv_df['upload-date'], otv_df['ratings'])\n",
    "plt.suptitle('Ratings by Date', fontsize=26)\n",
    "plt.xlabel('Date', fontsize=16)\n",
    "plt.ylabel('Ratings', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#perform polynomial fit on the datapoints\n",
    "otv_df['upload-date-num']=otv_df['upload-date'].map(datetime.datetime.toordinal)\n",
    "trend = np.polyfit(otv_df['upload-date-num'].to_numpy(), otv_df['rate-ratio'].to_numpy(), 2)\n",
    "trendpoly = np.poly1d(trend) \n",
    "#plot ratio of likes with relation to time\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.scatter(otv_df['upload-date'], otv_df['rate-ratio'])\n",
    "plt.suptitle('Percentage of Viewers that Rate by Date', fontsize=26)\n",
    "plt.xlabel('Date', fontsize=16)\n",
    "plt.ylabel('Percentage of Ratings', fontsize=16)\n",
    "plt.plot(otv_df['upload-date-num'], trendpoly(otv_df['upload-date-num']))\n",
    "plt.show()\n",
    "fig.savefig('graphs/rate_ratio_over_time.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate statistics\n",
    "like_avg = otv_df['like-ratio'].mean() * 100\n",
    "like_avg = str(round(like_avg, 2))\n",
    "dislike_avg = otv_df['dislike-ratio'].mean() * 100\n",
    "dislike_avg = str(round(dislike_avg, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "printDict(common_tag)": "<em>OfflineTV</em> : <strong>32</strong><br><em>Scarra</em> : <strong>32</strong><br><em>Poki</em> : <strong>32</strong><br><em>Pokimane</em> : <strong>32</strong><br><em>Lily</em> : <strong>32</strong><br><em>DisguisedToast</em> : <strong>32</strong><br><em>Toast</em> : <strong>32</strong><br><em>TwitchTV</em> : <strong>32</strong><br><em>twitch</em> : <strong>32</strong><br><em>Streaming</em> : <strong>32</strong><br><em>Vlog</em> : <strong>32</strong><br><em>Fail</em> : <strong>32</strong><br><em>Epic</em> : <strong>32</strong><br><em>Gamers</em> : <strong>32</strong><br><em>Streamers</em> : <strong>32</strong><br><em>OTV</em> : <strong>32</strong><br><em>OTV Plays</em> : <strong>32</strong><br><em>OfflineTV plays</em> : <strong>32</strong><br><em>Lilypichu Voice</em> : <strong>31</strong><br><em>Pokimane thicc</em> : <strong>31</strong>  ",
     "printDict(common_title)": "<em>OFFLINETV</em> : <strong>22</strong><br><em>ft.</em> : <strong>14</strong><br><em>-</em> : <strong>12</strong><br><em>Scarra</em> : <strong>11</strong><br><em>Michael</em> : <strong>10</strong><br><em>LilyPichu</em> : <strong>10</strong><br><em>DisguisedToast</em> : <strong>9</strong><br><em>Fedmyster</em> : <strong>9</strong><br><em>Reeves</em> : <strong>8</strong><br><em>Pokimane</em> : <strong>7</strong>  ",
     "unique_tag": "4.52",
     "unique_title": "40.33"
    }
   },
   "source": [
    "## Lexical Statistics in Titles and Tags  \n",
    "\n",
    "*NLTK: Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. Oâ€™Reilly Media Inc.*\n",
    "\n",
    "**Most Common Words in Title:**  \n",
    "{{printDict(common_title)}}\n",
    "\n",
    "**Most Common Words in Tags:**  \n",
    "{{printDict(common_tag)}}  \n",
    "\n",
    "**Lexical Diversity**  \n",
    "*Percent of Unique Words in Title:* **{{unique_title}}%**  \n",
    "*Percent of Unique Words in Tags:* **{{unique_tag}}%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of words in title\n",
    "titles = []\n",
    "#create list with all words in title\n",
    "for title in otv_df['title']:\n",
    "    title_list = title.split()\n",
    "    for word in title_list:\n",
    "        titles.append(word)\n",
    "#frequency distribution of words in title\n",
    "fddist_titles = nltk.FreqDist(titles)\n",
    "common_title = fddist_titles.most_common(10)\n",
    "#frequency of words in tags\n",
    "tags = []\n",
    "#create list with all words in tags\n",
    "for tag in otv_df['tags']:\n",
    "    tag_list = tag.split(',')\n",
    "    for word in tag_list:\n",
    "        tags.append(word)\n",
    "#frequency distribution of words in tags\n",
    "fddist_tags = nltk.FreqDist(tags)\n",
    "common_tag = fddist_tags.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print out a dictionary \n",
    "def printDict(dictionary):\n",
    "    for key, value in dictionary:\n",
    "        print(\"*\" + key + \"*\" + \" : **\" + str(value) + \"**  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each unique word in titles\n",
    "words_titles = sorted(set(titles))\n",
    "words_titles = [x.strip(')') for x in words_titles]\n",
    "words_titles = [x.strip('(') for x in words_titles]\n",
    "words_titles = [x.replace('(', '') for x in words_titles]\n",
    "words_titles = [x.replace(')', '') for x in words_titles]\n",
    "words_titles = set(word.lower() for word in words_titles if word.isalpha())\n",
    "#each unique tag\n",
    "words_tags = sorted(set(tags))\n",
    "words_tags = set(word.lower() for word in words_tags if word.isalpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the lexical diversity\n",
    "#of title\n",
    "unique_title = (len(words_titles) / len(titles)) * 100\n",
    "unique_title = round(unique_title, 2)\n",
    "#of tags\n",
    "unique_tag = (len(words_tags) / len(tags)) * 100\n",
    "unique_tag = round(unique_tag, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
